{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256798ee",
   "metadata": {},
   "source": [
    "# Alpha-Beta-CROWN demos\n",
    "These three demos are ready to run in Colab with lightweight guidance:\n",
    "- Image classification certifies a logit ordering inside an L-infinity pixel box.\n",
    "- Lyapunov checks a controller + Lyapunov candidate on Van der Pol.\n",
    "- Robot reachability inspects one safe step and one unsafe step side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b2e1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from abcrown import (\n",
    "    ABCrownSolver,\n",
    "    ConfigBuilder,\n",
    "    VerificationSpec,\n",
    "    input_vars,\n",
    "    output_vars,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d193a4e4",
   "metadata": {},
   "source": [
    "## Image classification (expression spec)\n",
    "- Builds an L-infinity box around a random 28x28 grayscale image.\n",
    "- Verifies that logit0 is the max of three logits.\n",
    "- Uses a tiny CNN with random weights.\n",
    "\n",
    "Step-by-step (modular cells)\n",
    "- Step 1: Compute graph — tiny conv net mapping 1x28x28 to 3 logits.\n",
    "- Step 2: Spec — declare symbolic inputs/outputs; constrain inputs to the L-infinity box; enforce logit0 > logit1 and logit0 > logit2.\n",
    "- Step 3: Config — just use defaults.\n",
    "- Step 4: Solve — create the solver with spec/model/config, call solve(), and inspect result.status/result.success.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb3e340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: compute graph (tiny CNN)\n",
    "class SimpleConvClassifier(torch.nn.Module):\n",
    "    \"\"\"CNN that maps 1x28x28 input to 3 logits.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.head = torch.nn.Linear(16 * 28 * 28, 3)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if x.ndim == 2:\n",
    "            x = x.view(x.shape[0], 1, 28, 28)\n",
    "        feats = self.conv(x)\n",
    "        flat = feats.view(feats.shape[0], -1)\n",
    "        return self.head(flat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6760225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: spec builder (symbolic vars + constraints)\n",
    "def build_image_classification_spec(base_image: torch.Tensor, eps: float):\n",
    "    \"\"\"Construct spec with L-infinity box and logit ordering.\"\"\"\n",
    "    x = input_vars((1, 28, 28))\n",
    "    y = output_vars(3)\n",
    "    input_constraint = (x >= (base_image - eps)) & (x <= (base_image + eps))\n",
    "    output_constraint = (y[0] > y[1]) & (y[0] > y[2])\n",
    "    spec = VerificationSpec.build_spec(\n",
    "        input_vars=x,\n",
    "        output_vars=y,\n",
    "        input_constraint=input_constraint,\n",
    "        output_constraint=output_constraint,\n",
    "    )\n",
    "    return spec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d38ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: config (defaults)\n",
    "def build_demo_config():\n",
    "    \"\"\"Config for the image classification spec.\"\"\"\n",
    "    return (\n",
    "        ConfigBuilder.from_defaults()\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e3d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: solver + one-shot run\n",
    "def solve_image_classification(base_image: torch.Tensor, eps: float = 0.02):\n",
    "    \"\"\"Run ABCrown on the image classification spec.\"\"\"\n",
    "    spec = build_image_classification_spec(base_image, eps)\n",
    "    model = SimpleConvClassifier()\n",
    "    solver = ABCrownSolver(spec, model, config=build_demo_config())\n",
    "    result = solver.solve()\n",
    "    print(\"[image classification] base eps=\", eps)\n",
    "    print(f\"status={result.status}, success={result.success}\")\n",
    "    return result\n",
    "\n",
    "torch.manual_seed(15)\n",
    "base_image = torch.rand(1, 1, 28, 28)\n",
    "_ = solve_image_classification(base_image, eps=0.02)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d83d6e",
   "metadata": {},
   "source": [
    "## Lyapunov (Van der Pol)\n",
    "- Reuses the tutorial computation graph (controller + Lyapunov NN + dynamics).\n",
    "- Input box: |x_i| ≤ 0.5.\n",
    "- Output constraints: V(x) > 0, V_dot < 0.\n",
    "\n",
    "Step-by-step (modular cells)\n",
    "- Step 1: Compute graph — assemble dynamics, controller, and Lyapunov networks.\n",
    "- Step 2: Spec — clamp the state box and require v_min < V(x) < v_max while V_dot(x) < 0.\n",
    "- Step 3: Config — reuse the defaults with `{\"model\": {\"with_jacobian\": True}}`.\n",
    "- Step 4: Solve — run the solver once and inspect status/success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febc8cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: compute graph (Van der Pol + controller + Lyapunov network)\n",
    "from neural_lyapunov_dependency.computation_graph import (\n",
    "    Controller,\n",
    "    Lyapunov,\n",
    "    VanDerPolDynamics,\n",
    "    LyapunovComputationGraph,\n",
    ")\n",
    "\n",
    "def build_lyapunov_model() -> LyapunovComputationGraph:\n",
    "    dynamics = VanDerPolDynamics()\n",
    "    controller = Controller(\n",
    "        dims=[2, 10, 10, 1],\n",
    "        x_equilibrium=dynamics.x_equilibrium,\n",
    "        u_equilibrium=dynamics.u_equilibrium,\n",
    "        scale=1.0,\n",
    "    )\n",
    "    lyapunov = Lyapunov(dims=[2, 40, 40, 1])\n",
    "    model = LyapunovComputationGraph(dynamics, controller, lyapunov)\n",
    "    ckpt = \"neural_lyapunov_dependency/seed_0.pth\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    try:\n",
    "        state = torch.load(ckpt, map_location=device)\n",
    "        state_dict = state[\"state_dict\"] if isinstance(state, dict) and \"state_dict\" in state else state\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load checkpoint from {ckpt}: {e}\")\n",
    "    return model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b54588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: spec builder (state box + V constraints)\n",
    "def build_lyapunov_spec():\n",
    "    x = input_vars(2)\n",
    "    y = output_vars(2)  # y[0] = V(x), y[1] = V_dot\n",
    "    # Input box: x0 in [-4.8, 4.8], x1 in [-10.8, 10.8].\n",
    "    input_constraint = (x >= [-4.8, -10.8]) & (x <= [4.8, 10.8])\n",
    "    output_constraint = (y[0] < 0.0106) | (y[0] > 0.989) | (y[1] < 0.0)\n",
    "    return VerificationSpec.build_spec(\n",
    "        input_vars=x,\n",
    "        output_vars=y,\n",
    "        input_constraint=input_constraint,\n",
    "        output_constraint=output_constraint,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc969c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: config (Lyapunov verification)\n",
    "def build_lyapunov_config():\n",
    "    \"\"\"Config for the Lyapunov verification demo.\"\"\"\n",
    "    return (\n",
    "        ConfigBuilder.from_defaults().set(model__with_jacobian=True)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b2ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: solver helper (instantiate solver + print result)\n",
    "def solve_lyapunov_demo():\n",
    "    spec = build_lyapunov_spec()\n",
    "    model = build_lyapunov_model()\n",
    "    solver = ABCrownSolver(spec, model, config=build_lyapunov_config())\n",
    "    result = solver.solve()\n",
    "\n",
    "    print(\"[lyapunov] verifying Van der Pol controller\")\n",
    "\n",
    "    print(f\"status={result.status}, success={result.success}\")\n",
    "    return result\n",
    "\n",
    "_ = solve_lyapunov_demo()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7133f3f4",
   "metadata": {},
   "source": [
    "## Robot reachability (discrete scalar)\n",
    "- **What is verified:** a one-dimensional closed-loop update $x^+ = g x$ stays inside $[-0.8, 0.8]$ for every $x$ in $[-1, 1]$.\n",
    "- The dynamics are intentionally tiny so the safe/unsafe outcome is transparent.\n",
    "- A contraction gain (|g| < 1) keeps the state inside the safety band, while an expansion gain (|g| > 1) pushes some states outside.\n",
    "\n",
    "Step-by-step (modular cells)\n",
    "- Step 1: Compute graph — scalar closed-loop model that returns $|x^+|$.\n",
    "- Step 2: Spec — bound $x$ and enforce a single inequality $0.8 - |x^+| \\ge 0$.\n",
    "- Step 3: Config — build a default config.\n",
    "- Step 4: Solve — run the safe gain (should certify) and the unsafe gain (should fail).\n",
    "\n",
    "<img src=\"figures/drone_demo.png\" width=\"60%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d04046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: compute graph (scalar closed-loop dynamics)\n",
    "class ScalarClosedLoop(torch.nn.Module):\n",
    "    \"\"\"Single-step scalar update that returns |x^+|.\"\"\"\n",
    "\n",
    "    def __init__(self, gain: float) -> None:\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"gain\", torch.tensor(float(gain), dtype=torch.float32))\n",
    "\n",
    "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        if state.ndim == 0:\n",
    "            state = state.unsqueeze(0)\n",
    "        if state.ndim == 1:\n",
    "            state = state.unsqueeze(1)\n",
    "        next_state = self.gain * state\n",
    "        return next_state.abs()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9974fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: spec builder (scalar bounds using expression DSL)\n",
    "def build_scalar_reachability_spec(initial_bound: float = 1.0, target_bound: float = 0.8) -> VerificationSpec:\n",
    "    \"\"\"Reachability spec: |x| <= initial_bound, |x^+| <= target_bound.\"\"\"\n",
    "    x = input_vars(1)\n",
    "    y = output_vars(1)  # y = |x^+|\n",
    "    input_constraint = (x >= -initial_bound) & (x <= initial_bound)\n",
    "    output_constraint = y[0] < target_bound\n",
    "    return VerificationSpec.build_spec(\n",
    "        input_vars=x,\n",
    "        output_vars=y,\n",
    "        input_constraint=input_constraint,\n",
    "        output_constraint=output_constraint,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4905ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: config (discrete scalar reachability)\n",
    "def build_robot_config():\n",
    "    \"\"\"Config for the scalar reachability demo.\"\"\"\n",
    "    return (\n",
    "        ConfigBuilder.from_defaults()\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc44e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: solver helper (instantiate solver + report stats)\n",
    "def run_scalar_reachability_case(label: str, gain: float):\n",
    "    \"\"\"Instantiate scalar dynamics, solve reachability, and print summary.\"\"\"\n",
    "\n",
    "    spec = build_scalar_reachability_spec()\n",
    "    model = ScalarClosedLoop(gain=gain)\n",
    "    solver = ABCrownSolver(spec, model, config=build_robot_config())\n",
    "    result = solver.solve()\n",
    "\n",
    "    print(f\"[scalar {label}] dynamics: x^+ = {gain:.2f} * x\")\n",
    "    print(\"input bound: |x| <= 1.0, target bound: |x^+| < 0.8\")\n",
    "    print(f\"status={result.status}, success={result.success}\\n\")\n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"Case 1: contraction gain (expected safe)\")\n",
    "_ = run_scalar_reachability_case(\"safe\", gain=0.5)\n",
    "\n",
    "print(\"Case 2: expansion gain (expected unsafe)\")\n",
    "_ = run_scalar_reachability_case(\"unsafe\", gain=1.2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abcrown_pip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
